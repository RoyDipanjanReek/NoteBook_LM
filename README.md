# ğŸ§  NotebookLM Clone â€” RAG-powered AI Notes Assistant

A **Retrieval-Augmented Generation (RAG)** powered note-taking and knowledge assistant inspired by **Googleâ€™s NotebookLM**.  
Built with **Next.js**, **LangChain**, **Docker**, **OpenAI**, and **Clerk** â€” this app allows users to upload documents, query their own data, and get context-aware AI answers.

---

## ğŸš€ Features

- ğŸ“„ **Document Uploads** â€” Upload PDFs, text, or CSV files for context-based learning
- ğŸ§© **RAG Pipeline** â€” Uses LangChain for document chunking, embeddings, and retrieval
- ğŸ¤– **Chat with Your Notes** â€” Contextual chat with OpenAIâ€™s GPT models
- ğŸ” **Authentication with Clerk** â€” Secure user management and session handling
- âš¡ **Next.js App Router** â€” Modern, fast, and scalable React-based framework
- ğŸ§  **Vector Store Integration** â€” Store embeddings in Qdrant 
- ğŸ’¾ **Persistent Conversations** â€” Save chat history and revisit your notes anytime
- ğŸ¨ **Modern UI** â€” Built with Tailwind CSS & Shadcn UI for a clean notebook feel

---

## ğŸ—ï¸ Tech Stack

| Category     | Technology                                                                                                                                    |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Frontend     | [Next.js 14](https://nextjs.org/), [React](https://react.dev/), [Tailwind CSS](https://tailwindcss.com/), [Shadcn UI](https://ui.shadcn.com/) |
| Backend      | [LangChain](https://www.langchain.com/), [Next.js API Routes](https://nextjs.org/docs/pages/building-your-application/routing/api-routes)     |
| AI / LLM     | [OpenAI API](https://platform.openai.com/docs)                                                                                                |
| Auth         | [Clerk](https://clerk.com/)                                                                                                                   |
| Vector DB    | [QdrantDB](https://qdrant.tech/)                                                                                                              |
| File Parsing | [PDF-Parse](https://www.npmjs.com/package/pdf-parse), [PapaParse](https://www.papaparse.com/)                                                 |

---

## ğŸ§© Project Structure

```
notebooklm-clone/
â”‚
â”œâ”€â”€ app/ # Next.js app router
â”‚ â”œâ”€â”€ layout.tsx
â”‚ â”œâ”€â”€ page.tsx
â”‚ â””â”€â”€ api/
â”‚ â”œâ”€â”€ chat/route.ts # Chat endpoint for AI responses
â”‚ â””â”€â”€ upload/route.ts # File upload & embedding processing
â”‚
â”œâ”€â”€ components/ # Reusable UI components
â”œâ”€â”€ lib/
â”‚ â”œâ”€â”€ langchain/ # LangChain pipelines and retrievers
â”‚ â”œâ”€â”€ embeddings.ts # OpenAI embeddings setup
â”‚ â””â”€â”€ qdrant.ts # Vector DB integration
â”‚
â”œâ”€â”€ public/ # Static assets
â”œâ”€â”€ styles/ # Tailwind & global styles
â”œâ”€â”€ .env.local # Environment variables
â””â”€â”€ README.md
```

---

## âš™ï¸ Environment Variables

Create a `.sample.env` file in the project root:

``` bash
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_key
CLERK_SECRET_KEY=your_clerk_secret

OPENAI_API_KEY=your_openai_api_key

QDRANT_URL=https://your-qdrant-instance
QDRANT_API_KEY=your_qdrant_api_key

## ğŸ› ï¸ Installation & Setup
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/yourusername/notebooklm-clone.git
cd notebooklm-clone

# 2ï¸âƒ£ Install dependencies
npm install

# 3ï¸âƒ£ Setup environment variables
cp  .sample.env

# 4ï¸âƒ£ Run the development server
npm run dev

Visit your app at ğŸ‘‰ http://localhost:3000
```

## ğŸ§  RAG Pipeline Overview

```
1ï¸âƒ£ Document Upload: User uploads a file (PDF, text, etc.)

2ï¸âƒ£ Text Extraction: The file content is parsed and split into chunks

3ï¸âƒ£ Embeddings Creation: Each chunk is converted into vector embeddings using OpenAI

4ï¸âƒ£ Vector Storage: Embeddings are stored in a vector database (Qdrant)

6ï¸âƒ£ Query: When user asks a question, relevant chunks are retrieved using similarity search

7ï¸âƒ£ LLM Response: OpenAI generates a context-aware answer based on retrieved context
```

# ğŸ§ª Example Query Flow

```mermaid
flowchart TD
    A[User Query] --> B[LangChain Retriever]
    B --> C[Vector Store Similarity Search]
    C --> D[Relevant Context]
    D --> E[OpenAI GPT Model]
    E --> F[Final Answer]
```

## ğŸªª License

This project is licensed under the MIT License.

## â­ Acknowledgements

LangChain

Next.js

Clerk

OpenAI

Qdrant

Docker

Google NotebookLM
â€” inspiration for this project.

## ğŸ’¡ Future Enhancements

Add multi-document retrieval

Support for image/document summarization

Semantic search with hybrid retrieval

Collaborative workspaces

## ğŸ§‘â€ğŸ“ Author

## Dipanjan Roy

ğŸš€ Passionate about AI, backend development, and building meaningful projects.

### [LinkedIn](https://www.linkedin.com/in/roydipanjan2003/)

### [GitHub](https://github.com/RoyDipanjanReek)

### [Portfolio](https://nextjs.org/)

---
